<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" lang="en" xml:lang="en">
<head>
<META http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>Task: Run Acceptance Test Cases</title>
<meta name="uma.type" content="Task">
<meta name="uma.name" content="run_acceptance_test_cases">
<meta name="uma.presentationName" content="Run Acceptance Test Cases">
<meta name="uma.category" content="Discipline:tech_test:Technical Testing">
<meta name="element_type" content="activity">
<meta name="filetype" content="description">
<meta name="role" content="Test Specialist">
<link rel="StyleSheet" href="./../../css/default.css" type="text/css">
<script src="./../../scripts/ContentPageResource.js" type="text/javascript" language="JavaScript"></script><script src="./../../scripts/ContentPageSection.js" type="text/javascript" language="JavaScript"></script><script src="./../../scripts/ContentPageSubSection.js" type="text/javascript" language="JavaScript"></script><script src="./../../scripts/ContentPageToolbar.js" type="text/javascript" language="JavaScript"></script><script src="./../../scripts/contentPage.js" type="text/javascript" language="JavaScript"></script><script type="text/javascript" language="JavaScript">
					var backPath = './../../';
					var imgPath = './../../images/';
					var nodeInfo=[{view: "view:_NEaN8M6vEdy9E5kgF3Gy4g", path: ["_NEaN8M6vEdy9E5kgF3Gy4g", "_RJ__ECLJEd2ct852UDqXGQ", "_WCIHY8RdEdyD76CYS6Ta7A", "_zjDbdWkdEd63b_Plx7Kd_g", "_safIIGptEeSdxcAgtnf5og", "_5ukJkFmXEd-RLsfIF0kO2g"]}, {view: "view:_NEaN8M6vEdy9E5kgF3Gy4g", path: ["_NEaN8M6vEdy9E5kgF3Gy4g", "_kpou0CmJEd65FoKJYXtPqg", "_vLdhkLUuEdyZzqoEHUdEQA", "_H0dQkLUvEdyZzqoEHUdEQA", "_5ukJkFmXEd-RLsfIF0kO2g"]}];
					contentPage.preload(imgPath, backPath, nodeInfo, '', true, false, false);
				</script>
</head>
<body>
<div id="breadcrumbs"></div>
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr>
<td valign="top">
<div id="page-guid" value="_5ukJkFmXEd-RLsfIF0kO2g"></div>
<table border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td class="pageTitle" nowrap="true">Task: Run Acceptance Test Cases</td><td width="100%">
<div align="right" id="contentPageToolbar"></div>
</td>
</tr>
</table>
<table width="100%" border="0" cellpadding="0" cellspacing="0">
<tr>
<td class="pageTitleSeparator"><img src="./../../images/shim.gif" alt="" title="" height="1"></td>
</tr>
</table>
<div class="overview">
<table width="97%" border="0" cellspacing="0" cellpadding="0">
<tr>
<td width="50"><img src="./../../images/task.gif" alt="" title=""></td><td>
<table class="overviewTable" border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top">Carry out test cases on user acceptance test. </td>
</tr>
<tr>
<td>Disciplines: <a href="./../../core.default.cat_def.base-ibm_lic/disciplines/tech_test_65BE95A1.html" guid="_H0dQkLUvEdyZzqoEHUdEQA">Technical Testing</a></td>
</tr>
</table>
</td>
</tr>
</table>
</div>
<div class="sectionHeading">Purpose</div>
<div class="sectionContent">
<table class="sectionTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<td class="sectionTableSingleCell">To carry out the Acceptance Test Execution Plan, produce Acceptance test results, and identify variances between expected
Acceptance test results and actual Acceptance test results. Successful&nbsp;user acceptance&nbsp;test&nbsp;helps ensure
business needs have been met and the system is ready for production with a high degree of confidence<br /></td>
</tr>
</table>
</div>
<div class="sectionHeading">Relationships</div>
<div class="sectionContent">
<table class="sectionTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<th class="sectionTableHeading" scope="row">Roles</th><td class="sectionTableCell" width="42%"><span class="sectionTableCellHeading">Primary Performer:
								</span>
<ul>
<li>
<a href="./../../core.default.role_def.base-ibm_lic/roles/test_specialist_EBC2F1A0.html" guid="mweb70BAB7D6643F3326852568D8004A6107">Test Specialist</a>
</li>
</ul>
</td><td class="sectionTableCell"><span class="sectionTableCellHeading">Additional Performers:
								</span></td>
</tr>
<tr valign="top">
<th class="sectionTableHeading" scope="row">Inputs</th><td class="sectionTableCell" width="42%"><span class="sectionTableCellHeading">Mandatory:
								</span>
<ul>
<li>
<a href="./../../core.tech.common.extend-ibm_lic/workproducts/build_FADD57B5.html" guid="mwebF9113618D6FEA03685256882006F7E1E">Build</a>
</li>
</ul>
<ul></ul>
</td><td class="sectionTableCell"><span class="sectionTableCellHeading">Optional:
								</span>
<ul>
<li>
<a href="./../../core.tech.common.extend-ibm_lic/workproducts/test_execution_plan_40CC18DC.html" guid="mweb05F01C330983D99E85256885005D2982">Test Execution Plan</a>
</li>
<li>
<a href="./../../core.tech.common.extend-ibm_lic/workproducts/test_specification_E0A1A8C5.html" guid="mwebCE3B2E307A951B9485256885005D8027">Test Specification</a>
</li>
</ul>
<ul></ul>
</td>
</tr>
<tr valign="top">
<th class="sectionTableHeading" scope="row">Outputs</th><td class="sectionTableCell" colspan="2">
<ul>
<li>
<a href="./../../core.legacy.common_wp.base-ibm_lic/workproducts/defect_analysis_doc_F51B0306.html" guid="mweb11676D7D5BCC2E2E852569A40072E01E">Defect Analysis Document</a>
</li>
<li>
<a href="./../../core.tech.common.extend-ibm_lic/workproducts/test_log_BEB93BFD.html" guid="_Da0ikGE7EeC2hZk9_GMypg">Test Log</a>
</li>
</ul>
<ul></ul>
</td>
</tr>
</table>
</div>
<div class="sectionHeading">Main Description</div>
<div class="sectionContent">
<table class="sectionTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<td class="sectionTableSingleCell"><p>
    This task follows the activities laid out in the Acceptance Test Execution Plan and the Acceptance Test Specification
    to produce actual test results. Execution activities are logged. Information is captured about the process, such as the
    condition of the Acceptance test data and environment before, at specified points during, and after, the Acceptance
    test execution, as well as any unexpected or unscripted events. This will be used to diagnose the variances in the next
    task. The results themselves may be documented or captured in a test tools or Acceptance files for comparison purposes.
    They are linked to the details of the actual run that produced them, in paper or electronic files or databases.
</p>
<p>
    User acceptance testing starts upon successful completion of&nbsp; system integration testing and when the user
    acceptance test plan is reviewed, approved by the Stakeholders, and placed under baseline control. User acceptance
    tests ends upon successful execution of all UAT test cases and the business users have approved the results. User
    acceptance testing is. conducted to enable a user, client, or other authorized entity to determine whether or not to
    accept a system.
</p></td>
</tr>
</table>
</div>
<div class="sectionHeading">Steps</div>
<div class="sectionContent">
<table class="sectionTable" border="0" cellspacing="0" cellpadding="0">
<tr>
<td class="sectionTableSingleCell">
<div class="stepHeading">Conduct acceptance test and verify results</div>
<div class="stepContent">
<table class="stepTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<td>This task follows the activities laid out in the acceptance test execution plan and the acceptance test specification to
produce actual test results. Execution activities are logged. Information is captured about the process, such as the
condition of the Acceptance test data and environment before, at specified points during, and after, the acceptance test
execution, as well as any unexpected or unscripted events. This will be used to diagnose the variances in the next task.
The results themselves may be documented or captured in a test tools or acceptance files for comparison purposes. They are
linked to the details of the actual run that produced them, in paper or electronic files or databases.</td>
</tr>
</table>
</div>
<div class="stepHeading">Verify acceptance test results</div>
<div class="stepContent">
<table class="stepTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<td>The actual acceptance test results are compared to the expected results and any variances identified and recorded. This may
be done manually or with a variety of test automation tools. The critical success factor is being able to link variances
with enough details of the acceptance test run which produced them to allow diagnosis of the cause in the next task. The
test execution control sheet is used to show whether a particular condition, scenario or cycle has been successfully tested
and to document any variances. This includes confirmation against technical specifications under test, such as performance
and capacity measurements. All discrepancies, however minor, are recorded and require resolution or explanation. The test
executor should not dismiss any difference as unimportant. Refer to defect management for raising defects, test reporting
and root cause analysis.</td>
</tr>
</table>
</div>
<div class="stepHeading">Analyze and resolve acceptance test variances</div>
<div class="stepContent">
<table class="stepTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<td>The variances identified from checking results are analyzed to determine their cause. Analysis of the variance may indicate
the cause of the problem to be a defect or may result in a change request. If it is caused by a defect, an impact analysis
is required to estimate the effort and time to fix it. The resolution is documented. If the analysis results in a change
request the variance is closed and the resolution is documented. <br />
<br />
Variances encountered during test execution will typically fall into the following categories:<br />
<br />
1. Testing Process Errors. 
<ul>
    <li>
        Acceptance Test Execution Errors: The test executor did not follow the script to the letter.
    </li>
    <li>
        Acceptance Test Data Error: The original data created to test the condition did not meet the specification of the
        test data model for the condition.
    </li>
    <li>
        Acceptance Test Script Error<i>:</i> The instructions or responses stated in the script were incorrect.
    </li>
    <li>
        Acceptance Test Configuration Error<i>:</i> The environment was incorrectly configured.
    </li>
</ul><br />
2. Business or Technical Functional Errors. 
<ul>
    <li>
        Programming Error: The code does not match the detailed design.
    </li>
    <li>
        Design Error: The design does not meet the functional requirements.
    </li>
</ul><br />
Variances that are the result of testing process errors usually require the process to be remedied and the test to be
repeated. These errors should also be reviewed to ensure that they have not impacted previous test results.</td>
</tr>
</table>
</div>
<div class="stepHeading">Retest acceptance defects</div>
<div class="stepContent">
<table class="stepTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<td>Once defects have been fixed they are re-tested. Re-testing will usually involve not only re-executing the failed test(s)
but may also include a regression set of tests, where appropriate, to ensure that new errors have not been introduced with
the fix. If the fix has worked, the condition can be checked off as being successfully tested. The resolution of all
defects should be carefully documented and signed-off. This information is an important deliverable, that combined with the
Actual Results, proves that the Acceptance Test level is ready for sign-off.</td>
</tr>
</table>
</div>
<div class="stepHeading">Conduct deployment trial runs</div>
<div class="stepContent">
<table class="stepTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<td>Carry out trial tests to ensure that proper deployment will take place.&nbsp; If the production environment is being used
for the trial run, performance characteristics should be recorded during this procedure.</td>
</tr>
</table>
</div>
<div class="stepHeading">Report acceptance test results and status</div>
<div class="stepContent">
<table class="stepTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<td><p>
    The status report is a summary of the test results for the reporting period. It includes analysis of result
    information. It describes how well the detailed level of testing is progressing. It may be automatically generated from
    the test tool suite or compiled manually.<br />
    <br />
    Some of the measurements produced are:
</p>
<ul>
    <li>
        Number of defects found.
    </li>
    <li>
        Severity levels.
    </li>
    <li>
        Status of defects - outstanding, investigated, explained, fixed, re-tested, accepted, etc.
    </li>
    <li>
        Rate of arrival; i.e., defects found per test executed and / or per tested product component, by test period and
        level.
    </li>
</ul>
<p>
    The test status report provides an overall summary of the testing progress. It identifies those activities completed in
    the current reporting period and those planned for the next. Any issues, problems, and risks are also noted. These
    reports include information on planned tasks, planned schedule, the actual status of both tasks and schedule, the
    forecasted outlook, issues, recommendations and an action plan . The objective is to:
</p>
<ul>
    <li>
        Review actual status against plan.
    </li>
    <li>
        Identify and address constraints, concerns and issues.
    </li>
    <li>
        Identify items requiring containment and/or escalation to resolve issues.
    </li>
</ul>Appropriate consolidation and filtering of data is necessary to ensure the key information is input and assimilated at
the respective planning level meetings.Any statistically valid conclusions that can be drawn from these analyses are used
to predict the quality level achieved by the tested product and compared to the target level established in the test plans.</td>
</tr>
</table>
</div>
</td>
</tr>
</table>
</div>
<table class="copyright" border="0" cellspacing="0" cellpadding="0">
<tr>
<td class="copyright">&copy; &nbsp;Copyright IBM Corp.&nbsp;1987, 2012&nbsp;All Rights Reserved <br />
Property of IBM <br />
These&nbsp;materials are intended&nbsp;only for use as part of an IBM engagement</td>
</tr>
</table>
</td>
</tr>
</table>
</body>
<script type="text/javascript" language="JavaScript">
				contentPage.onload();
			</script>
</html>
