<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" lang="en" xml:lang="en">
<head>
<META http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>Task: Run System Integration Test Cases</title>
<meta name="uma.type" content="Task">
<meta name="uma.name" content="run_system_integration_test_cases">
<meta name="uma.presentationName" content="Run System Integration Test Cases">
<meta name="uma.category" content="Discipline:tech_test:Technical Testing">
<meta name="element_type" content="activity">
<meta name="filetype" content="description">
<meta name="role" content="Test Specialist">
<link rel="StyleSheet" href="./../../css/default.css" type="text/css">
<script src="./../../scripts/ContentPageResource.js" type="text/javascript" language="JavaScript"></script><script src="./../../scripts/ContentPageSection.js" type="text/javascript" language="JavaScript"></script><script src="./../../scripts/ContentPageSubSection.js" type="text/javascript" language="JavaScript"></script><script src="./../../scripts/ContentPageToolbar.js" type="text/javascript" language="JavaScript"></script><script src="./../../scripts/contentPage.js" type="text/javascript" language="JavaScript"></script><script type="text/javascript" language="JavaScript">
					var backPath = './../../';
					var imgPath = './../../images/';
					var nodeInfo=[{view: "view:_NEaN8M6vEdy9E5kgF3Gy4g", path: ["_NEaN8M6vEdy9E5kgF3Gy4g", "_RJ__ECLJEd2ct852UDqXGQ", "_WCIHY8RdEdyD76CYS6Ta7A", "_2MqpYGeSEd6Yrd44J2HAGg", "_sdxssGptEeSdxcAgtnf5og", "_3rGDsFmcEd-RLsfIF0kO2g"]}, {view: "view:_NEaN8M6vEdy9E5kgF3Gy4g", path: ["_NEaN8M6vEdy9E5kgF3Gy4g", "_kpou0CmJEd65FoKJYXtPqg", "_vLdhkLUuEdyZzqoEHUdEQA", "_H0dQkLUvEdyZzqoEHUdEQA", "_3rGDsFmcEd-RLsfIF0kO2g"]}];
					contentPage.preload(imgPath, backPath, nodeInfo, '', true, false, false);
				</script>
</head>
<body>
<div id="breadcrumbs"></div>
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr>
<td valign="top">
<div id="page-guid" value="_3rGDsFmcEd-RLsfIF0kO2g"></div>
<table border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td class="pageTitle" nowrap="true">Task: Run System Integration Test Cases</td><td width="100%">
<div align="right" id="contentPageToolbar"></div>
</td>
</tr>
</table>
<table width="100%" border="0" cellpadding="0" cellspacing="0">
<tr>
<td class="pageTitleSeparator"><img src="./../../images/shim.gif" alt="" title="" height="1"></td>
</tr>
</table>
<div class="overview">
<table width="97%" border="0" cellspacing="0" cellpadding="0">
<tr>
<td width="50"><img src="./../../images/task.gif" alt="" title=""></td><td>
<table class="overviewTable" border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top">Carry out test cases on system integration test.</td>
</tr>
<tr>
<td>Disciplines: <a href="./../../core.default.cat_def.base-ibm_lic/disciplines/tech_test_65BE95A1.html" guid="_H0dQkLUvEdyZzqoEHUdEQA">Technical Testing</a></td>
</tr>
</table>
</td>
</tr>
</table>
</div>
<div class="sectionHeading">Purpose</div>
<div class="sectionContent">
<table class="sectionTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<td class="sectionTableSingleCell">Execute the planned Systems Integration Tests, ensuring that the networked system has been comprehensively tested as
planned, and that any defects are identified and managed.</td>
</tr>
</table>
</div>
<div class="sectionHeading">Relationships</div>
<div class="sectionContent">
<table class="sectionTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<th class="sectionTableHeading" scope="row">Roles</th><td class="sectionTableCell" width="42%"><span class="sectionTableCellHeading">Primary Performer:
								</span>
<ul>
<li>
<a href="./../../core.default.role_def.base-ibm_lic/roles/test_specialist_EBC2F1A0.html" guid="mweb70BAB7D6643F3326852568D8004A6107">Test Specialist</a>
</li>
</ul>
</td><td class="sectionTableCell"><span class="sectionTableCellHeading">Additional Performers:
								</span></td>
</tr>
<tr valign="top">
<th class="sectionTableHeading" scope="row">Inputs</th><td class="sectionTableCell" width="42%"><span class="sectionTableCellHeading">Mandatory:
								</span>
<ul></ul>
<ul>
<li>
<a href="./../../core.tech.slot.base/workproducts/technical_implementation_slot_E92F6A39.html" guid="_Vux8UEfUEdyiPI8btkmvmw">[Technical Implementation]</a>
<ul>
<li>
<a href="./../../core.tech.common.extend-ibm_lic/workproducts/build_FADD57B5.html" guid="mwebF9113618D6FEA03685256882006F7E1E">Build</a>
</li>
<li>
<a href="./../../core.tech.common.extend-ibm_lic/workproducts/deployment_packaging_125B66B6.html" guid="_PXlk0FBLEeC-nZrGQNBVmA">Deployment Packaging</a>
</li>
<li>
<a href="./../../core.gen.common.extend-ibm_lic/workproducts/learning_solution_materials_13D6A889.html" guid="_6nBJcFAJEeCS0rTrMFdSqw">Learning Solution Materials</a>
</li>
<li>
<a href="./../../core.tech.common.extend-ibm_lic/workproducts/media_content_462FFB4B.html" guid="_S_LWkFBLEeC-nZrGQNBVmA">Media Content</a>
</li>
<li>
<a href="./../../core.tech.common.extend-ibm_lic/workproducts/source_files_EFC2C2F9.html" guid="mweb3A52A85C8665725C85256885005B699F">Source Files</a>
</li>
<li>
<a href="./../../core.gen.common.extend-ibm_lic/workproducts/user_support_materials_8752BE4D.html" guid="_9M5mkFAJEeCS0rTrMFdSqw">User Support Materials</a>
</li>
</ul>
</li>
</ul>
</td><td class="sectionTableCell"><span class="sectionTableCellHeading">Optional:
								</span>
<ul>
<li>
<a href="./../../core.tech.common.extend-ibm_lic/workproducts/test_execution_plan_40CC18DC.html" guid="mweb05F01C330983D99E85256885005D2982">Test Execution Plan</a>
</li>
<li>
<a href="./../../core.tech.common.extend-ibm_lic/workproducts/test_specification_E0A1A8C5.html" guid="mwebCE3B2E307A951B9485256885005D8027">Test Specification</a>
</li>
</ul>
<ul></ul>
</td>
</tr>
<tr valign="top">
<th class="sectionTableHeading" scope="row">Outputs</th><td class="sectionTableCell" colspan="2">
<ul>
<li>
<a href="./../../core.legacy.common_wp.base-ibm_lic/workproducts/defect_analysis_doc_F51B0306.html" guid="mweb11676D7D5BCC2E2E852569A40072E01E">Defect Analysis Document</a>
</li>
<li>
<a href="./../../core.tech.common.extend-ibm_lic/workproducts/test_log_BEB93BFD.html" guid="_Da0ikGE7EeC2hZk9_GMypg">Test Log</a>
</li>
</ul>
<ul></ul>
</td>
</tr>
</table>
</div>
<div class="sectionHeading">Main Description</div>
<div class="sectionContent">
<table class="sectionTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<td class="sectionTableSingleCell"><p>
    Ensure testing resources are in place: people, data, environment and facilities. Follow the execution plan procedures
    to perform the actual tests. Capture the results as planned. Analyze the variance to discover the cause of the problem:
    defect or change request. If it is caused by a defect, an impact analysis is required to estimate the effort and time
    to fix it. The resolution is documented. If the analysis results in a change request the variance is closed and the
    resolution is documented.<br />
</p></td>
</tr>
</table>
</div>
<div class="sectionHeading">Steps</div>
<div class="sectionContent">
<table class="sectionTable" border="0" cellspacing="0" cellpadding="0">
<tr>
<td class="sectionTableSingleCell">
<div class="stepHeading">Conduct system integration test</div>
<div class="stepContent">
<table class="stepTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<td>This step follows the activities laid out in the Systems Integration Test Execution Plan and the Systems Integration Test
Specification to produce actual test results. Execution activities are logged. Information is captured about the process,
such as the condition of the Systems Integration test data and environment before, at specified points during, and after,
the Systems Integration test execution, as well as any unexpected or unscripted events. This will be used to diagnose the
variances in the next task. The results themselves may be documented or captured in a test tools or Systems Integration
files for comparison purposes. They are linked to the details of the actual run that produced them, in paper or electronic
files or databases.</td>
</tr>
</table>
</div>
<div class="stepHeading">Verify results</div>
<div class="stepContent">
<table class="stepTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<td><p>
    The actual Systems Integration test results are compared to the expected results and any variances identified and
    recorded. This may be done manually or with a variety of test automation tools. The critical success factor is being
    able to link variances with enough details of the Systems Integration test run which produced them to allow diagnosis
    of the cause in the next task. The test execution control sheet is used to show whether a particular condition,
    scenario or cycle has been successfully tested and to document any variances. This includes confirmation against
    technical specifications under test, such as performance and capacity measurements. All discrepancies, however minor,
    are recorded and require resolution or explanation. The test executor should not dismiss any difference as unimportant.
    Refer to Defect Management for raising defects, test reporting and root cause analysis.<br />
    <br />
    Test Execution Plan contains the following information:
</p>
<ul>
    <li>
        Systems Integration Test Cycle
    </li>
    <li>
        Systems Integration Test Scenario
    </li>
    <li>
        Test Step
    </li>
    <li>
        Detailed Test Condition
    </li>
    <li>
        Actual Results
    </li>
    <li>
        Expected Results
    </li>
    <li>
        Notes (to assist analysis)
    </li>
    <li>
        Defect reference number
    </li>
</ul>It is structured so that all relevant details of a discrepancy can be captured at the time of detection. Control
sheets are not usually required formally as a final deliverable but are used during execution. As each detailed test
condition is satisfied, i.e., no unexplained and unacceptable variances are present, it is signed-off and dated by the test
executor.</td>
</tr>
</table>
</div>
<div class="stepHeading">Analyze and resolve system integration test variances</div>
<div class="stepContent">
<table class="stepTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<td>The variances identified from checking results are analyzed to determine their cause. Analysis of the variance may indicate
the cause of the problem to be a defect or may result in a change request. If it is caused by a defect, an impact analysis
is required to estimate the effort and time to fix it. The resolution is documented. If the analysis results in a change
request the variance is closed and the resolution is documented. <br />
<br />
Variances encountered during test execution will typically fall into the following categories: 
<ol>
    <li>
        Testing Process Errors.
    </li>
    <li style="LIST-STYLE-TYPE: none">
        <ul>
            <li>
                <strong>Test Execution Errors:</strong> The test executor did not follow the script to the letter.
            </li>
            <li>
                <strong>Test Data Error:</strong> The original data created to test the condition did not meet the
                specification of the test data model for the condition.
            </li>
            <li>
                <strong>Test Script Error:</strong> The instructions or responses stated in the script were incorrect.
            </li>
            <li>
                <strong>Test Configuration Error:</strong> The environment was incorrectly configured.
            </li>
        </ul>
    </li>
</ol>
<ol start="2">
    <li>
        Business or Technical Functional Errors.
    </li>
    <li style="LIST-STYLE-TYPE: none">
        <ul>
            <li>
                <strong>Programming Error:</strong> The code does not match the detailed design.
            </li>
            <li>
                <strong>Design Error:</strong> The design does not meet the functional requirements.
            </li>
        </ul>
    </li>
</ol>Variances that are the result of testing process errors usually require the process to be remedied and the test to be
repeated. These errors should also be reviewed to ensure that they have not impacted previous test results.<br />
<br />
Variances that are the result of conflicts between the requirements, specification and / or design and its actual execution
are investigated to determine whether they are true defects or a miscommunication of expectations. The former are referred
to the defect management process and rated for severity and priority for fixing as assigned by the master test plan and the
defect management team. The latter are referred to the change management process to prioritize the revision of
requirements, specification, design and construction of each item. (These items will eventually re-enter the testing
process as defined by the management of the change request.) <br />
<br />
Once defects have been fixed they are re-tested. Re-testing will usually involve re-executing not only the failed test(s)
but a regression set of tests which will ensure that new errors have not been introduced with the fix. If the fix has
worked, the condition can be checked off as being successfully tested. The resolution of all defects should be carefully
documented and signed-off. This information is an important deliverable, that combined with the Actual Results, proves that
the test level/phase is ready for sign-off.</td>
</tr>
</table>
</div>
<div class="stepHeading">Retest system integration defects</div>
<div class="stepContent">
<table class="stepTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<td>Once defects have been fixed they are re-tested. Re-testing will usually involve not only re-executing the failed test(s)
but may also include a regression set of tests, where appropriate, to ensure that new errors have not been introduced with
the fix. If the fix has worked, the condition can be checked off as being successfully tested. The resolution of all
defects should be carefully documented and signed-off. This information is an important deliverable, that combined with the
Actual Results, proves that the System Integration Test level is ready for sign-off.</td>
</tr>
</table>
</div>
<div class="stepHeading">Report system integration test results and status</div>
<div class="stepContent">
<table class="stepTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<td><p>
    The status report is a summary of the test results for the reporting period. It includes analysis of result
    information. It describes how well the detailed level of testing is progressing. It may be automatically generated from
    the test tool suite or compiled manually.<br />
    <br />
    Some of the measurements produced are:
</p>
<ul>
    <li>
        Number of defects found.
    </li>
    <li>
        Severity levels.
    </li>
    <li>
        Status of defects - outstanding, investigated, explained, fixed, re-tested, accepted, etc.
    </li>
    <li>
        Rate of arrival; i.e., defects found per test executed and / or per tested product component, by test period and
        level.
    </li>
</ul>
<p>
    The test status report provides an overall summary of the testing progress. It identifies those activities completed in
    the current reporting period and those planned for the next. Any issues, problems, and risks are also noted. These
    reports include information on planned tasks, planned schedule, the actual status of both tasks and schedule, the
    forecasted outlook, issues, recommendations and an action plan . The objective is to:
</p>
<ul>
    <li>
        Review actual status against plan.
    </li>
    <li>
        Identify and address constraints, concerns and issues.
    </li>
    <li>
        Identify items requiring containment and/or escalation to resolve issues.
    </li>
</ul>Appropriate consolidation and filtering of data is necessary to ensure the key information is input and assimilated at
the respective planning level meetings.&nbsp;Any statistically valid conclusions that can be drawn from these analyses are
used to predict the quality level achieved by the tested product and compared to the target level established in the test
plans.</td>
</tr>
</table>
</div>
</td>
</tr>
</table>
</div>
<table class="copyright" border="0" cellspacing="0" cellpadding="0">
<tr>
<td class="copyright">&copy; &nbsp;Copyright IBM Corp.&nbsp;1987, 2012&nbsp;All Rights Reserved <br />
Property of IBM <br />
These&nbsp;materials are intended&nbsp;only for use as part of an IBM engagement</td>
</tr>
</table>
</td>
</tr>
</table>
</body>
<script type="text/javascript" language="JavaScript">
				contentPage.onload();
			</script>
</html>
