<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" lang="en" xml:lang="en">
<head>
<META http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>Task Descriptor: Design the Acceptance Test Specification</title>
<meta name="uma.type" content="TaskDescriptor">
<meta name="uma.name" content="design_acceptance_test_spec">
<meta name="uma.presentationName" content="Design the Acceptance Test Specification">
<meta name="uma.guid" content="_G6Flfd0jEd-Yr79L5-CRdw">
<meta name="element_type" content="TaskDescriptor">
<meta name="filetype" content="description">
<meta name="role" content="">
<link rel="StyleSheet" href="./../../css/default.css" type="text/css">
<script src="./../../scripts/ContentPageResource.js" type="text/javascript" language="JavaScript"></script><script src="./../../scripts/ContentPageSection.js" type="text/javascript" language="JavaScript"></script><script src="./../../scripts/ContentPageSubSection.js" type="text/javascript" language="JavaScript"></script><script src="./../../scripts/ActivityTreeTable.js" type="text/javascript" language="JavaScript"></script><script src="./../../scripts/ProcessElementPage.js" type="text/javascript" language="JavaScript"></script><script src="./../../scripts/ContentPageToolbar.js" type="text/javascript" language="JavaScript"></script><script src="./../../scripts/contentPage.js" type="text/javascript" language="JavaScript"></script><script src="./../../scripts/processElementData.js" type="text/javascript" language="JavaScript"></script><script type="text/javascript" language="JavaScript">
					var defaultQueryStr = '?proc=_g91Ka9uSEd-uj6_0XU4muw&path=_g91Ka9uSEd-uj6_0XU4muw,_G6Fk8N0jEd-Yr79L5-CRdw,_G6FlgN0jEd-Yr79L5-CRdw,_G6Flfd0jEd-Yr79L5-CRdw';
					var backPath = './../../';
					var imgPath = './../../images/';
					var nodeInfo=null;
					contentPage.preload(imgPath, backPath, nodeInfo, defaultQueryStr, true, true, false);
				</script>
</head>
<body>
<div id="breadcrumbs"></div>
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr>
<td valign="top">
<div id="page-guid" value="_G6Flfd0jEd-Yr79L5-CRdw"></div>
<table border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td class="pageTitle" nowrap="true">Task Descriptor: Design the Acceptance Test Specification</td><td width="100%">
<div align="right" id="contentPageToolbar"></div>
</td>
</tr>
</table>
<table width="100%" border="0" cellpadding="0" cellspacing="0">
<tr>
<td class="pageTitleSeparator"><img src="./../../images/shim.gif" alt="" title="" height="1"></td>
</tr>
</table>
<div class="overview">
<table width="97%" border="0" cellspacing="0" cellpadding="0">
<tr>
<td width="50"><img src="./../../images/taskdes_lg_dgm32.gif" alt="" title=""></td><td>
<table class="overviewTable" border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top">Design user acceptance test specification.</td>
</tr>
<tr>
<td>Based on Method Task: <a href="./../../practice.tech.acceptance_testing.base-ibm_lic/tasks/design_acceptance_test_spec_7EF1C7B9.html" guid="_uWQNgFmXEd-RLsfIF0kO2g">Design the Acceptance Test Specification</a></td>
</tr>
</table>
</td>
</tr>
</table>
</div>
<div class="sectionHeading">Relationships</div>
<div class="sectionContent">
<table class="sectionTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<th class="sectionTableHeading" scope="row">Roles</th><td class="sectionTableCell" width="30%"><span class="sectionTableCellHeading">Primary:
								</span>
<ul>
<li>
<a href="./../../process.tech.ad_20.base-ibm_int/deliveryprocesses/test_specialist_76776DD5.html" guid="_G6FldN0jEd-Yr79L5-CRdw">Test Specialist</a>
</li>
</ul>
</td><td class="sectionTableCell" width="30%"><span class="sectionTableCellHeading">Additional:
								</span>
<ul>
<li>
<a href="./../../process.tech.ad_20.base-ibm_int/deliveryprocesses/test_architect_F8D22639.html" guid="_G6Flft0jEd-Yr79L5-CRdw">Test Architect</a>
</li>
</ul>
</td><td class="sectionTableCell"><span class="sectionTableCellHeading">Assisting:
								</span></td>
</tr>
<tr valign="top">
<th class="sectionTableHeading" scope="row">Inputs</th><td class="sectionTableCell" width="30%"><span class="sectionTableCellHeading">Mandatory:
								</span>
<ul>
<li>
<a href="./../../process.tech.ad_20.base-ibm_int/deliveryprocesses/technical_specification_slot_3440441A.html" guid="_G6Flet0jEd-Yr79L5-CRdw">[Technical Specification]</a>
</li>
</ul>
</td><td class="sectionTableCell" width="30%"><span class="sectionTableCellHeading">Optional:
								</span>
<ul>
<li>
<a href="./../../process.tech.ad_20.base-ibm_int/deliveryprocesses/technical_approach_slot_8F6A15D0.html" guid="_G6FlT90jEd-Yr79L5-CRdw">[Technical Approach]</a>
</li>
<li>
<a href="./../../process.tech.ad_20.base-ibm_int/deliveryprocesses/acceptance_test_plan_6465192.html" guid="_G6FlR90jEd-Yr79L5-CRdw">Acceptance Test Plan</a>
</li>
<li>
<a href="./../../process.tech.ad_20.base-ibm_int/deliveryprocesses/test_env_config_9D6C7BCD.html" guid="_G6FlRt0jEd-Yr79L5-CRdw">Test Environment Configuration</a>
</li>
<li>
<a href="./../../process.tech.ad_20.base-ibm_int/deliveryprocesses/test_specification_EB22222A.html" guid="_G6FlUt0jEd-Yr79L5-CRdw">Test Specification</a>
</li>
</ul>
</td><td class="sectionTableCell"><span class="sectionTableCellHeading">External:
								</span>
<ul>
<li>None</li>
</ul>
</td>
</tr>
<tr valign="top">
<th class="sectionTableHeading" scope="row">Outputs</th><td class="sectionTableCell" colspan="3">
<ul>
<li>
<a href="./../../process.tech.ad_20.base-ibm_int/deliveryprocesses/test_case_AFB40449.html" guid="_G6FlVt0jEd-Yr79L5-CRdw">Test Case</a>
</li>
<li>
<a href="./../../process.tech.ad_20.base-ibm_int/deliveryprocesses/test_data_53FBF7EF.html" guid="_G6FlU90jEd-Yr79L5-CRdw">Test Data</a>
</li>
<li>
<a href="./../../process.tech.ad_20.base-ibm_int/deliveryprocesses/test_env_config_9D6C7BCD.html" guid="_G6FlRt0jEd-Yr79L5-CRdw">Test Environment Configuration</a>
</li>
<li>
<a href="./../../process.tech.ad_20.base-ibm_int/deliveryprocesses/test_script_188DDA0E.html" guid="_G6FlV90jEd-Yr79L5-CRdw">Test Script</a>
</li>
<li>
<a href="./../../process.tech.ad_20.base-ibm_int/deliveryprocesses/test_specification_EB22222A.html" guid="_G6FlUt0jEd-Yr79L5-CRdw">Test Specification</a>
</li>
</ul>
</td>
</tr>
</table>
</div>
<div class="sectionHeading">Steps</div>
<div class="sectionContent">
<table class="sectionTable" border="0" cellspacing="0" cellpadding="0">
<tr>
<td class="sectionTableCell">
<div class="stepHeading">Select testing techniques and tools for acceptance testing</div>
<div class="stepContent">
<table class="stepTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<td>Select the different testing tools and techniques to improve the effectiveness and the efficiency of the test. The tools
selected must focus on achieving the test objectives and the overall testing strategy. The identification of the
purchasing, implementation and training requirements associated with the different options.<br />
<br />
All the techniques listed above are industry standard techniques. Education on some of the white and black box techniques
can be found in the TPM Overview and TPM Workshop course. <br />
<br />
<b>Techniques Guidance</b><br />
<br />
Requirements-based tests should employ Black Box testing techniques. User requirements can be tested without knowledge of
the internal design specification or the code. Tests are based on the requirements document but formulated by using the
functional design specification. Function-based tests should also employ the use of Black Box testing techniques. Using the
function design specification to design function-based tests is both necessary and sufficient. The requirements and
internal design specifications are unnecessary for function-based tests. Select the applicable Black Box techniques from
the following list: 
<ul>
    <li>
        Equivalence partitioning
    </li>
    <li>
        Boundary-value analysis
    </li>
    <li>
        Cause-effect graphing
    </li>
    <li>
        Syntax testing (generating both valid and invalid input data to a program)
    </li>
    <li>
        Error guessing
    </li>
</ul>Evaluate the usefulness of incorporating selected White Box techniques where they complement the Black Box testing
techniques<br />
<br />
Tools to support the Acceptance Test include: 
<ul dir="ltr" style="MARGIN-RIGHT: 0px">
    <li>
        Simulation Tools: simulation of large numbers of terminals (this is limited by capability of the operating system
        to support concurrent processes) 
        <ul>
            <li>
                The ability to increase or decrease progressively the number of terminals on-line
            </li>
            <li>
                The ability to record and play back multiple operator sessions
            </li>
            <li>
                The ability to duplicate tests across large numbers of terminals
            </li>
            <li>
                The ability to control remotely tests running on each terminal
            </li>
            <li>
                The ability to synchronize precisely the tests on each terminal (to test concurrent access, for example)
            </li>
            <li>
                The ability to measure system response from the viewpoint of each terminal
            </li>
            <li>
                The ability to read data from a central test data source
            </li>
            <li>
                The ability to accumulate and analyze test results centrally
            </li>
        </ul>
    </li>
    <li>
        Test Automation
    </li>
    <li>
        Test Drivers 
        <ul>
            <li>
                Provides for regression testing
            </li>
            <li>
                Used for volume test to vary load statistically and dynamically
            </li>
            <li>
                Ability to drive a large variety of system types, e.g., telephone call generators
            </li>
            <li>
                Used to validate IT work performed (e.g., check the returned message content, preferably while the test is
                executing and produce error messages when incorrect
            </li>
        </ul>
    </li>
    <li>
        Data Creation Tools
    </li>
    <li>
        Reporting Tools 
        <ul>
            <li>
                Automatically updates the test repository on completion of a test run
            </li>
            <li>
                Gives you the option of updating the repository
            </li>
            <li>
                Lets you view selected results data in real-time
            </li>
            <li>
                Generates statistical reports on performance ratings against various load conditions across the system
            </li>
            <li>
                Generates reports of failures detected at each
            </li>
            <li>
                Views test results that relate to each terminal on a summary screen
            </li>
            <li>
                Provides graphical versions of statistical
            </li>
            <li>
                Provides report customization and formatting
            </li>
        </ul>
    </li>
    <li>
        Monitoring and Analysis Tools 
        <ul>
            <li>
                Provides real-time and historical recording for later analysis
            </li>
            <li>
                Provides format structures for recording the data
            </li>
            <li>
                Assist in data reduction and statistical analysis - especially from volume tests where a log record may be
                produced for every "transaction"
            </li>
        </ul>
    </li>
    <li>
        Debugging Tools 
        <ul>
            <li>
                Assists in finding and correcting the cause of a fault or failure in an application
            </li>
        </ul>
    </li>
</ul></td>
</tr>
</table>
</div>
<div class="stepHeading">Develop acceptance test design</div>
<div class="stepContent">
<table class="stepTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<td>Requirements-based tests should be developed in parallel with the Requirements Definition. A requirement is not really a
requirement unless it is testable. How can it be objectively determined whether a requirement has been met or not unless
there is a mechanism for measuring it, i.e. a test? The Acceptance Criteria should be defined by the users during
Requirements Definition and will help to validate the requirements. These acceptance criteria should be reviewed and
signed-off in parallel with the Requirements Definition.<br />
<br />
The requirements-based tests should be developed from the Acceptance Criteria and the External Design. Some examples for
structuring tests are by: 
<ul>
    <li>
        Transaction flows
    </li>
    <li>
        Process flows
    </li>
    <li>
        Special conditions
    </li>
    <li>
        Sections of the Requirements Definition
    </li>
</ul>The tests should aim to test: 
<ul>
    <li>
        Acceptance of all valid classes of system input.
    </li>
    <li>
        Rejection of all invalid classes of system input.
    </li>
    <li>
        All functions.
    </li>
    <li>
        All classes of system outputs.
    </li>
    <li>
        All effective states.
    </li>
    <li>
        All interfacing systems and procedures.
    </li>
    <li>
        All non-functional requirements such as required response times to user actions at screens,&nbsp;etc.
    </li>
</ul>The Business Users and Developers, utilizing the Users’ ‘detailed business knowledge and Developers’ technical
expertise resulting in more comprehensive and effective tests, should develop these tests cooperatively. The involvement of
Users in developing the tests should also increase their confidence in the system and reduce the need for separate
Acceptance Testing.<br />
<br />
The requirements-based tests for the systems’ functionality should be developed first, followed by the technical tests like
performance, etc.<br />
<br />
<b>Ensure Testability</b><br />
<br />
In order to be able to assess if an output meets or exceeds a given expectation, the expectation must be stated in testable
terms. This means that when the characteristics of an output under test are compared against the expected characteristics,
they can be matched in a clear and unambiguous way. You would not request that the answer to a calculation of (1 + 4) is to
be an appropriate amount. To be testable, you would specify the answer as a single value like 5 or as a range between 0 and
10 if the exact answer were not known. If the result of the test were anything other than 5 or a number within the
specified range, the test would unequivocally fail and you would record the variance. The example, of course, is trivial
but it serves to illustrate the point.<br />
<br />
While you may strive to have requirements stated in testable terms, it may not always be possible. The required level of
detail when you document and test the requirements may not yet be available. The process of requirements specification and
the High Level Physical Process Model should evolve the functional request from a collection of imprecise statements of
user needs to testable user specifications. Even though the root of the word specification is specific, achieving specific
requirements is an extremely challenging exercise. At every point in the specification process, you can check the
‘testability’ of the requirement or specification by ensuring it is S.M.A.R.T. This acronym stands for:<br />
<br />
S - Specific<br />
<br />
M - Measurable<br />
<br />
A - Attainable<br />
<br />
R - Realistic<br />
<br />
T - Timely.<br />
<br />
These specifications will form the basis for the criteria upon which the system is tested and ultimately accepted by the
system owner and end-user.<br />
<br />
Review the exhibit, Requirements Testability guidelines to avoid typical problems, i.e., vague statements, unsupported
assertions, difficult or impossible test environment, high problem complexity, confusion between business objectives and
systems objectives.</td>
</tr>
</table>
</div>
<div class="stepHeading">Analyze available data and build acceptance test data</div>
<div class="stepContent">
<table class="stepTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<td>As part of the test planning process, the test data requirements are defined and set up. Test scripts must be created
containing both valid and invalid test data. This involves identifying data that will support the test, allow it to execute
as designed and provide meaningful output to measure against expected results.<br />
<br />
As part of this task, potential sources for test data are determined. The methods are identified to extract additional or
new data. Data from sources such as existing production and data from previous testing activities are examined to determine
the data required to perform this level of testing. Modifying existing data and supplementing them with additional data as
required build test data.<br />
<br />
The processes required to support the data are also defined. For example: 
<ul>
    <li>
        How will data be built or extracted?
    </li>
    <li>
        How often will it be backed up?
    </li>
    <li>
        How, when and where will this data be maintained? By whom?
    </li>
</ul></td>
</tr>
</table>
</div>
<div class="stepHeading">Identify test environment requirements</div>
<div class="stepContent">
<table class="stepTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<td>Define both the necessary and desired properties of the Test Environment. Include enough information to plan for
establishing the environment but do not include a detailed specification of the environment itself - this should be
provided in the Test Specification document, which corresponds to this plan. This specification should include: 
<ul>
    <li>
        Identification of the physical components, the communications, the system and middleware necessary.
    </li>
    <li>
        The mode or state of usage (for example, standalone or dedicated to the discrete usage of the application alone).
    </li>
    <li>
        Other software or supplies needed to support testing (e.g. specialized stationery).
    </li>
    <li>
        Security and access requirements to the test area and equipment.
    </li>
    <li>
        Test tools and utilities required.
    </li>
    <li>
        Identify any other testing needs (publications, office space).
    </li>
    <li>
        Additional software licences to cover test period usage.
    </li>
    <li>
        Support resources and skills required to maintain the test environments.
    </li>
    <li>
        Identify a source for any of the needs that are not currently available to the test group.
    </li>
    <li>
        If any other projects are to make parallel usage of any of the above, reference it.
    </li>
</ul></td>
</tr>
</table>
</div>
<div class="stepHeading">Document acceptance test specifications including performance test specifications</div>
<div class="stepContent">
<table class="stepTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<td>To document for Acceptance Test level, the test cases for each test condition or group of conditions that will: 
<ul>
    <li>
        Test the specifications for what the system must do.
    </li>
    <li>
        Test the system the way it will be used.
    </li>
    <li>
        Perform destructive testing.
    </li>
</ul>Note: Ensure that Regression Testing is considered for modules that are being enhanced, fixed or modified in any way.</td>
</tr>
</table>
</div>
<div class="stepHeading">Finalize acceptance criteria and acceptance test specification sign off</div>
<div class="stepContent">
<table class="stepTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<td>Finalize the acceptance criteria identified in the detailed Acceptance Test Plan, finalize the Acceptance Test Plan and
obtain the necessary commitment from all the participating parties.</td>
</tr>
</table>
</div>
<div class="stepHeading">Review acceptance test specification</div>
<div class="stepContent">
<table class="stepTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<td><ul>
    <li>
        Ensure that acceptance test specification clearly defines&nbsp;and describes components
    </li>
    <li>
        Ensure that the acceptance test cases covers: 
        <ul>
            <li>
                Valid input/output conditions.
            </li>
            <li>
                Invalid and unexpected input/output conditions.
            </li>
        </ul>
    </li>
    <li>
        Ensure that the following have been completed as required:
    </li>
    <li style="LIST-STYLE-TYPE: none">
        <ul>
            <li>
                Test scenarios
            </li>
            <li>
                Test matrices
            </li>
            <li>
                Test conditions
            </li>
            <li>
                Test cases
            </li>
            <li>
                Test data
            </li>
            <li>
                Test scripts
            </li>
        </ul>
    </li>
    <li>
        Review and finalize the tools and techniques to be used in acceptance testing
    </li>
</ul></td>
</tr>
</table>
</div>
</td>
</tr>
</table>
</div>
<div class="sectionHeading">Properties</div>
<div class="sectionContent">
<table class="sectionTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<th class="sectionTableHeading" scope="row" id="property_Multiple Occurrences" abbr="Multiple Occurrences">Multiple Occurrences</th><td class="sectionTableCell" align="left" headers="property_Multiple Occurrences"><img width="20" height="15" alt="" title="" src="./../../images/indent.gif"></td>
</tr>
<tr valign="top">
<th class="sectionTableHeading" scope="row" id="property_Event Driven" abbr="Event Driven">Event Driven</th><td class="sectionTableCell" align="left" headers="property_Event Driven"><img width="20" height="15" alt="" title="" src="./../../images/indent.gif"></td>
</tr>
<tr valign="top">
<th class="sectionTableHeading" scope="row" id="property_Ongoing" abbr="Ongoing">Ongoing</th><td class="sectionTableCell" align="left" headers="property_Ongoing"><img width="20" height="15" alt="" title="" src="./../../images/indent.gif"></td>
</tr>
<tr valign="top">
<th class="sectionTableHeading" scope="row" id="property_Optional" abbr="Optional">Optional</th><td class="sectionTableCell" align="left" headers="property_Optional"><img width="20" height="15" alt="" title="" src="./../../images/indent.gif"></td>
</tr>
<tr valign="top">
<th class="sectionTableHeading" scope="row" id="property_Planned" abbr="Planned">Planned</th><td class="sectionTableCell" align="left" headers="property_Planned"><img width="20" height="15" alt="Yes" title="Yes" src="./../../images/true.gif"></td>
</tr>
<tr valign="top">
<th class="sectionTableHeading" scope="row" id="property_Repeatable" abbr="Repeatable">Repeatable</th><td class="sectionTableCell" align="left" headers="property_Repeatable"><img width="20" height="15" alt="" title="" src="./../../images/indent.gif"></td>
</tr>
</table>
</div>
<table class="copyright" border="0" cellspacing="0" cellpadding="0">
<tr>
<td class="copyright">&copy; &nbsp;Copyright IBM Corp.&nbsp;1987, 2012&nbsp;All Rights Reserved <br />
Property of IBM <br />
These&nbsp;materials are intended&nbsp;only for use as part of an IBM engagement</td>
</tr>
</table>
</td>
</tr>
</table>
</body>
<script language="JavaScript" type="text/javascript">
					contentPage.onload();
					contentPage.processPage.fixDescriptorLinks();
				</script>
</html>
